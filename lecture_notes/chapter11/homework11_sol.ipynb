{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based on chapter 11 of the course notes, and may introduce a few topics\n",
    "not mentioned there.\n",
    "\n",
    "You can also do the exercises at the bottom of the textbook chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sorted Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `L` is a list, then `sorted(L)` returns a sorted copy of the list, and\n",
    "`sorted(L, reverse=True)` returns a copy in reverse sorted order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd']\n",
      "['d', 'c', 'b', 'a']\n",
      "['b', 'a', 'd', 'c']\n"
     ]
    }
   ],
   "source": [
    "L = ['b', 'a', 'd', 'c']\n",
    "print(sorted(L))                # ['a', 'b', 'c', 'd']\n",
    "print(sorted(L, reverse=True))  # ['d', 'c', 'b', 'a']\n",
    "print(L)                        # ['b', 'a', 'd', 'c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program that prints the top 10 most frequently occurring *tokens* in a\n",
    "given text file. Convert all uppercase letters in the file to lowercase using\n",
    "the `lower` method.\n",
    "\n",
    "Use `split` to get the tokens of a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bob', 'said:', \"'hello,\", \"world!'\"]\n"
     ]
    }
   ],
   "source": [
    "s = \"  Bob   said:\\n\\n 'Hello, world!'\".lower()\n",
    "tokens = s.split()\n",
    "print(tokens)  # ['bob', 'said:', \"'hello,\", \"world!'\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the some tokens have non-letter characters, such as punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 10 tokens in the text file [austenPandP.txt](austenPandP.txt) are:\n",
    "\n",
    "```\n",
    "1. the (4480)\n",
    "2. to (4169)\n",
    "3. of (3678)\n",
    "4. and (3398)\n",
    "5. a (1982)\n",
    "6. her (1941)\n",
    "7. in (1889)\n",
    "8. was (1798)\n",
    "9. i (1739)\n",
    "10. she (1611)\n",
    "```\n",
    "\n",
    "Your program should print its output in the same format, and work for any text\n",
    "file.\n",
    "\n",
    "**Hint** [austenPandP.txt](austenPandP.txt) splits into exactly 124580 tokens,\n",
    "and the first 10 tokens are:\n",
    "\n",
    "```python\n",
    "['the', 'project', 'gutenberg', 'ebook', 'of', 'pride', 'and', 'prejudice,', 'by', 'jane']\n",
    "```\n",
    "\n",
    "Here are the 10 tokens starting at the 75th token:\n",
    "\n",
    "```python\n",
    "['date:', 'june,', '1998', 'language:', 'english', 'character', 'set', 'encoding:', 'ascii', '***']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124580\n",
      "['date:', 'june,', '1998', 'language:', 'english', 'character', 'set', 'encoding:', 'ascii', '***']\n",
      "1. the (4480)\n",
      "2. to (4169)\n",
      "3. of (3678)\n",
      "4. and (3398)\n",
      "5. a (1982)\n",
      "6. her (1941)\n",
      "7. in (1889)\n",
      "8. was (1798)\n",
      "9. i (1739)\n",
      "10. she (1611)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# sample solution\n",
    "#\n",
    "def second(t):\n",
    "    return t[1]\n",
    "\n",
    "fname = 'austenPandP.txt'\n",
    "tokens = open(fname).read().lower().split()\n",
    "print(len(tokens))\n",
    "start = 75\n",
    "print(tokens[start:start+10])\n",
    "token_count = {}\n",
    "for word in tokens:\n",
    "    if word in token_count:\n",
    "        token_count[word] += 1\n",
    "    else:\n",
    "        token_count[word] = 1\n",
    "\n",
    "sorted_tokens = sorted(token_count.items(), key=second, reverse=True)\n",
    "for i, (token, count) in enumerate(sorted_tokens[:10]):\n",
    "    print(f'{i+1}. {token} ({count})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
